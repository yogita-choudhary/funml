<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Lecture27 In-class Exercise</title>
  <link rel="stylesheet" href="../assets/style.css"/>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav>
  <a href="../index.html">Home</a>
</nav>
<main>
<div class="center">
<p><span><strong>In-Class Exercise (Canvas Quiz) â€” 10 minutes</strong></span><br />
<span><strong>Lecture 27: Uncertainty Quantification in Neural Networks</strong></span></p>
</div>
<p>This in-class quiz is based on Lecture 27 topics: aleatoric vs epistemic uncertainty, iterative methods (deep ensembles / MC-dropout), and evaluation metrics. You may assume natural log (<span class="math inline">\(\ln\)</span>) is used unless otherwise stated.</p>
<p><strong>Reminder:</strong> Entropy for a categorical distribution <span class="math inline">\(p\)</span> over classes: <span class="math display">\[H(p) = -\sum_{i} p_i \ln(p_i)\]</span></p>
<p><strong>Tasks:</strong> (Answer types: MC / True-False / Numeric)</p>
<ol>
<li><p><strong>(MC) Identify uncertainty type.</strong><br />
A neural network classifier performs poorly because input images have heavy snow/rain distortions during acquisition. Even with more training, predictions remain unreliable. Which uncertainty is this?</p>
<ul>
<li><p>Epistemic uncertainty</p></li>
<li><p>Aleatoric uncertainty</p></li>
<li><p>Neither (not uncertainty-related)</p></li>
<li><p>Both equally</p></li>
</ul></li>
<li><p><strong>(True/False) Reducibility of uncertainty.</strong><br />
<em>Epistemic uncertainty can often be reduced by collecting more data or improving the model.</em> <span class="math display">\[\text{True or False?}\]</span></p></li>
<li><p><strong>(MC) Iterative uncertainty estimation methods.</strong><br />
Which method applies dropout <em>at test time</em> and averages multiple stochastic forward passes?</p>
<ul>
<li><p>Standard Dropout</p></li>
<li><p>Monte Carlo Dropout (MC-Dropout)</p></li>
<li><p>Deterministic single-pass entropy</p></li>
<li><p>Brier Score</p></li>
</ul></li>
<li><p><strong>(Numeric) Entropy of a mean prediction.</strong><br />
Suppose deep ensembles produces the following <strong>mean predicted probabilities</strong> for a 3-class problem: <span class="math display">\[\bar{p} = [0.70,\;0.20,\;0.10]\]</span> Compute the entropy: <span class="math display">\[H(\bar{p}) = -\sum_{i=1}^3 \bar{p}_i \ln(\bar{p}_i)\]</span> Round your final answer to <strong>2 decimals</strong>.</p></li>
<li><p><strong>(MC) Performance metric category.</strong><br />
Negative Log-Likelihood (NLL) and Brier Score are examples of:</p>
<ul>
<li><p>Per-sample uncertainty metrics</p></li>
<li><p>Per-dataset uncertainty metrics</p></li>
<li><p>Active learning metrics</p></li>
<li><p>Calibration-free metrics</p></li>
</ul></li>
</ol>
<p><strong>Round all final numeric answers to 2 decimals.</strong></p>

</main>
</body>
</html>
