<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Lecture5 In-class Exercise</title>
  <link rel="stylesheet" href="../assets/style.css"/>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav>
  <a href="../index.html">Home</a>
</nav>
<main>
<div class="center">
<p><span><strong>In-Class Exercise (Canvas Quiz) — 10 minutes</strong></span><br />
<span><strong>Lecture 5: Introduction to Neural Networks (Single-Layer Perceptron)</strong></span></p>
</div>
<p><strong>Question 1</strong> Is the following statement True or False?</p>
<p><em>“In an SLP, If <span class="math inline">\(\mathbf{x} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\)</span> and both components of <span class="math inline">\(\mathbf{w}\)</span> are positive, then both weights will always increase during training.”</em></p>
<p><strong>Question 2</strong> Consider two training samples for a binary classifier:</p>
<p><strong>Sample A:</strong> <span class="math display">\[\mathbf{x}_A = \begin{bmatrix} 0.1 \\ 0.1 \end{bmatrix}, \quad y_A = 1\]</span></p>
<p><strong>Sample B:</strong> <span class="math display">\[\mathbf{x}_B = \begin{bmatrix} 10 \\ 10 \end{bmatrix}, \quad y_B = 1\]</span></p>
<p>Assume both samples produce the same error <span class="math inline">\(\delta = 0.5\)</span> (same under-prediction). Is the following statement True or False?</p>
<p>Since both samples have the same error, they will cause the same weight updates and contribute equally to learning.</p>

</main>
</body>
</html>
