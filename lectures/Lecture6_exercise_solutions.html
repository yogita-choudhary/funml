<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Lecture6 In-class Exercise Solutions</title>
  <link rel="stylesheet" href="../assets/style.css"/>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav>
  <a href="../index.html">Home</a>
</nav>
<main>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>_Lecture6_exercise_solutions</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="center">
<p><span><strong>In-Class Exercise â€” Solutions</strong></span><br />
<span><strong>Lecture 6: Classification Performance Evaluation</strong></span></p>
</div>
<p><strong>Question 1</strong></p>
<p>A dataset has <strong>95% class 0, 5% class 1</strong>.</p>
<p>A classifier predicts <strong>all samples as class 0</strong>.</p>
<p>Which of these statements is true?</p>
<p>(A) Accuracy is high and the model is good.</p>
<p>(B) Recall for class 1 is high.</p>
<p>(C) Precision for class 1 is undefined (or indeterminate <span class="math inline">\(\frac{0}{0}\)</span>).</p>
<p>(D) The classifier has learned meaningful decision boundaries.</p>
<p><strong>Solution:</strong> <strong>C</strong></p>
<p>Although its accuracy is <span class="math inline">\(95\%\)</span>, which is high, this classifier is not necessarily a good model if it only predicts class 0 all the time, as it is often used as a baseline, so (A) is incorrect.</p>
<p>The classifier predicts no positive (all negative) labels, so there are no true positives, and 5% of all predictions are false negatives, and <span class="math inline">\(\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\)</span>, so its recall is zero. (B) is incorrect.</p>
<p>The classifier predicts no positive labels, so there are no true positives or false positives, and <span class="math inline">\(\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\)</span>, so we get <span class="math inline">\(\text{Precision} = \frac{0}{0}\)</span>, which is indeterminate form (or undefined). <strong>(C) is correct.</strong></p>
<p>If a classifier has predicted all negative labels, it has never learned any meaningful decision boundary. Hence, (D) is incorrect.<br />
<strong>Question 2</strong></p>
<p>When training with <strong>class-weighted loss</strong>, increasing the weight of the minority class will:</p>
<p>(A) Reduce gradients from minority samples</p>
<p>(B) Increase gradients from minority samples</p>
<p>(C) Leave gradients unchanged</p>
<p>(D) Only affect evaluation metrics</p>
<p><strong>Solution:</strong> <strong>B</strong></p>
<p>Increasing the weight of the minority class multiplies the loss for those samples, which directly scales up their gradient contributions; hence, updates caused by minority samples become larger, and their impact on parameter learning becomes larger. <strong>(B) is correct.</strong><br />
<strong>Question 3</strong></p>
<p>Lowering the classification threshold for the positive class generally:</p>
<p>(A) Increases precision, decreases recall</p>
<p>(B) Increases recall, decreases precision</p>
<p>(C) Increases both precision and recall</p>
<p>(D) Has no effect</p>
<p><strong>Solution:</strong> <strong>B</strong></p>
<p><span class="math inline">\(\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\)</span></p>
<p><span class="math inline">\(\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\)</span></p>
<p>Lowering the classification threshold for the positive class increases the number of positive predictions, increasing the number of true positives (TP) and false positives (FP), decreasing the number of false negatives (FN).</p>
<p>Since FN decreases, the denominator <span class="math inline">\(\text{TP} + \text{FN}\)</span> shrinks and recall increases.</p>
<p>However, lowering the threshold allows more <em>low-confidence positive predictions</em>, which increases FP along with TP. Since FP increases, the denominator <span class="math inline">\(\text{TP} + \text{FP}\)</span> grows, so precision typically decreases.</p>
<p>Hence, recall increases wile precision decreases - <strong>(B) is correct</strong>.</p>
</body>
</html>

</main>
</body>
</html>
