\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, bm}
\usepackage{enumitem}

\begin{document}

\begin{center}
{\Large \textbf{In-Class Exercise (Canvas Quiz) --- 10 minutes}}\\[6pt]
{\large \textbf{Lecture 11: Clustering (k-Means)}}
\end{center}

\vspace{8pt}

\noindent
In k-Means, we assign each point to its closest centroid (Euclidean distance).
Equivalently, we can compare \textbf{squared distances} (to avoid square roots):
\[
d(\bm{x},\bm{m}_j)^2 = (x_1-m_{j1})^2 + (x_2-m_{j2})^2,
\qquad
\text{Cluster}(\bm{x})=\arg\min_j d(\bm{x},\bm{m}_j)^2.
\]
Tie-breaking rule: if there is a tie, choose the cluster with the \textbf{smallest index}.

\vspace{8pt}
\noindent
\textbf{Given centroids:}
\[
\bm{m}_1 = (2,3),\quad \bm{m}_2 = (7,8),\quad \bm{m}_3=(5,2)
\]
\textbf{New data point:}
\[
\bm{x}_{\text{new}} = (4,4)
\]

\vspace{10pt}


\footnotesize{
\noindent
\textbf{Questions (multiple choice):}

\noindent
\begin{minipage}[t]{0.48\textwidth}
\begin{enumerate}[label=(\arabic*), itemsep=10pt]
\item Which statement is correct?
\begin{itemize}
\item[(A)] Minimizing $d(\bm{x},\bm{m}_j)$ is different from minimizing $d(\bm{x},\bm{m}_j)^2$.
\item[(B)] Minimizing $d(\bm{x},\bm{m}_j)$ is equivalent to minimizing $d(\bm{x},\bm{m}_j)^2$.
\item[(C)] Squaring the distance changes the nearest centroid whenever distances are $<1$.
\end{itemize}
\end{enumerate}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\begin{enumerate}[label=(\arabic*), itemsep=10pt, start=2]
\item Compute the \textbf{squared distances} from $\bm{x}_{\text{new}}$ to each centroid.
Which option matches $(d_1^2,d_2^2,d_3^2)$?
\begin{itemize}
\item[(A)] $(5,\;25,\;5)$
\item[(B)] $(25,\;5,\;5)$
\item[(C)] $(5,\;20,\;4)$
\end{itemize}
\end{enumerate}
\end{minipage}

\vspace{10pt}

\noindent
\begin{minipage}[t]{0.48\textwidth}
\begin{enumerate}[label=(\arabic*), itemsep=10pt, start=3]
\item Which cluster should $\bm{x}_{\text{new}}$ be assigned to (using the given tie-breaking rule)?
\begin{itemize}
\item[(A)] Cluster 1
\item[(B)] Cluster 2
\item[(C)] Cluster 3
\end{itemize}
\end{enumerate}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\begin{enumerate}[label=(\arabic*), itemsep=10pt, start=4]
\item \textbf{Update step (centroid intuition).}  
After assignment, k-Means recomputes each centroid as the mean of points in that cluster.
If Cluster 1 currently contains exactly two points: $\bm{x}^{(1)}=(2,3)$ and $\bm{x}^{(2)}=(4,4)$, what is the updated centroid $\bm{m}_1$?
\begin{itemize}
\item[(A)] $(3,3.5)$
\item[(B)] $(3,4)$
\item[(C)] $(4,3.5)$
\end{itemize}
\end{enumerate}
\end{minipage}

\vspace{10pt}

\noindent
\begin{minipage}[t]{0.48\textwidth}
\begin{enumerate}[label=(\arabic*), itemsep=10pt, start=5]
\item \textbf{Convergence criterion.}  
Which condition indicates k-Means has converged (per lecture)?
\begin{itemize}
\item[(A)] Centroids stop changing (or change is negligible), so assignments also stop changing.
\item[(B)] Centroids keep changing but assignments stop changing.
\item[(C)] Assignments keep changing but centroids stop changing.
\end{itemize}
\end{enumerate}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\begin{enumerate}[label=(\arabic*), itemsep=10pt, start=6]
\item \textbf{Sensitivity / initialization (conceptual).}  
Which statement is true about k-Means?
\begin{itemize}
\item[(A)] k-Means always finds the global optimum regardless of initialization.
\item[(B)] k-Means can converge to a poor local solution depending on initialization.
\item[(C)] k-Means is not affected by outliers because it uses Euclidean distance.
\end{itemize}
\end{enumerate}
\end{minipage}
}





\end{document}
